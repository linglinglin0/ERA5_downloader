# ERA5 下载器 - 断点续传功能说明

## 📋 功能概述

增强版下载器(`ERA5download_GUI_v2.py`)新增了完整的**断点续传**功能,可以在网络中断、程序崩溃或手动停止后,从上次中断的位置继续下载,而不是重新开始。

---

## ✨ 核心特性

### 1. **真正的断点续传** (Range 请求)

#### 工作原理
- 使用 S3 `Range` 请求从指定字节位置继续下载
- 检测本地 `.tmp` 临时文件的大小作为断点位置
- 只下载缺失的部分,大幅节省时间和带宽

#### 技术实现
```python
# 使用 Range 请求续传
range_header = f"bytes={start_byte}-"
response = self.s3_client.get_object(
    Bucket=self.bucket_name,
    Key=f_info['Key'],
    Range=range_header
)
```

**示例**:
- 远程文件大小: 100MB
- 已下载: 60MB
- 续传时只下载: 40MB (60MB-100MB)

---

### 2. **进度状态持久化** (JSON 文件)

#### 状态文件
- **文件名**: `.era5_download_progress.json`
- **保存位置**: 下载目录内
- **内容**: 已完成的文件列表

#### 文件格式
```json
{
  "completed": [
    "e5.oper.an.pl.20251001_00.128_130_t.nc",
    "e5.oper.an.pl.20251001_00.128_130_u.nc"
  ],
  "date": "2026-01-19 20:45:30"
}
```

#### 功能
- ✅ 每完成一个文件,自动更新进度文件
- ✅ 重启程序后自动加载进度
- ✅ 跳过已完成的文件,继续下载未完成的

---

### 3. **智能重试机制**

#### 重试策略
- **最大重试次数**: 3 次(可配置 `self.max_retries`)
- **重试延迟**: 指数退避 (2秒 → 4秒 → 8秒)
- **适用场景**: 网络超时、连接中断、S3 服务错误

#### 重试流程
```
第一次下载失败 → 等待 2 秒 → 重试 1
   ↓ 失败
等待 4 秒 → 重试 2
   ↓ 失败
等待 8 秒 → 重试 3
   ↓ 失败
放弃下载,记录错误
```

#### 状态提示
- 下载中: `下载中`
- 重试中: `网络错误,4秒后重试(2/3)`
- 断点续传: `断点续传 60.5MB`

---

### 4. **临时文件管理**

#### 文件生命周期
```
开始下载 → 创建 .tmp 文件
   ↓
下载中 → 数据写入 .tmp (支持断点续传)
   ↓
下载完成 → 重命名为正式文件名
   ↓
清理 .tmp 进度文件 → 全部完成后
```

#### 停止行为变化
- **原版**: 停止时删除所有 `.tmp` 文件
- **增强版**: **保留** `.tmp` 文件供下次续传

**好处**:
- 网络中断后可以直接续传
- 不会丢失已下载的部分
- 重启程序后自动恢复

---

## 🚀 使用方法

### 1. 启动增强版
```bash
python ERA5download_GUI_v2.py
```

### 2. 正常下载流程
1. 选择日期和保存路径
2. 勾选需要的变量
3. 点击"开始下载"
4. 等待下载完成

### 3. 断点续传流程

#### 场景 1: 网络中断
```
1. 下载过程中网络断开
2. 程序自动重试(最多3次)
3. 重试成功后从断点继续下载
```

#### 场景 2: 手动停止
```
1. 点击"停止并关闭"
2. 临时文件(.tmp)被保留
3. 下次启动时自动继续下载
```

#### 场景 3: 程序崩溃
```
1. 程序意外退出
2. 重启程序
3. 选择相同的日期和路径
4. 点击"开始下载"
5. 程序自动跳过已完成的文件,继续未完成的
```

---

## 🔍 进度监控

### 监控面板信息

| 状态显示 | 含义 |
|---------|------|
| `开始下载...` | 从头开始下载 |
| `已存在(跳过)` | 文件已完整,跳过 |
| `不完整-重下` | 文件不完整,重新下载 |
| `断点续传 60.5MB` | 从 60.5MB 处继续下载 |
| `下载中` | 正常下载中 |
| `下载中 (重试1)` | 第一次重试 |
| `网络错误,4秒后重试(2/3)` | 等待重试 |
| `完成` | 文件下载完成 |
| `文件不完整` | 下载后大小不匹配 |

### 系统日志示例
```
正在扫描... 目标变量: ['t', 'u']
共 120 个文件,已完成 50,剩余 70
```

---

## ⚙️ 配置参数

### 可调整参数

```python
# 在 ERA5ResumeDownloadApp 类中修改

self.max_retries = 3          # 最大重试次数
self.retry_delay = 2          # 初始重试延迟(秒)
self.chunk_size = 8 * 1024 * 1024  # 分块大小(8MB)
```

### 推荐配置

| 场景 | max_retries | retry_delay | chunk_size |
|------|-------------|-------------|------------|
| 稳定网络 | 2 | 1 | 16MB |
| 一般网络 | 3 | 2 | 8MB (默认) |
| 不稳定网络 | 5 | 3 | 4MB |

**说明**:
- `chunk_size` 越大: 下载越快,但内存占用越高
- `retry_delay` 越小: 重试越快,但可能加重服务器负担
- `max_retries` 越大: 容错性越强,但等待时间越长

---

## 📊 性能对比

### 原版 vs 增强版

| 场景 | 原版 | 增强版 |
|------|------|--------|
| **正常下载** | 一次性下载 | 一次性下载 |
| **网络中断** | 从头开始 | 从断点续传 |
| **程序崩溃** | 从头开始 | 从断点续传 |
| **手动停止** | 删除临时文件 | 保留临时文件 |
| **重启程序** | 重新下载所有文件 | 跳过已完成文件 |

### 节省时间示例

假设下载 100 个文件,每个 100MB,总下载量 10GB:

| 场景 | 原版耗时 | 增强版耗时 | 节省时间 |
|------|---------|-----------|---------|
| **下载到 50% 时中断** | 5 小时(重新下载全部) | 2.5 小时(续传剩余50%) | **50%** |
| **下载到 90% 时中断** | 5 小时 | 0.5 小时 | **90%** |
| **网络频繁中断** | 无法完成 | 最终可完成 | **100%** |

---

## 🛠️ 故障排除

### 问题 1: 无法续传,显示"从头开始"

**原因**:
- 临时文件 `.tmp` 被删除
- 进度文件丢失或损坏

**解决方法**:
1. 检查下载目录是否有 `.tmp` 文件
2. 检查是否有 `.era5_download_progress.json`
3. 如果都没有,需要重新下载

---

### 问题 2: 显示"文件不完整"

**原因**:
- 下载后文件大小与远程不匹配
- 可能是 S3 对象在下载过程中被修改

**解决方法**:
1. 手动删除该 `.tmp` 文件
2. 重新开始下载

---

### 问题 3: 重试多次仍然失败

**原因**:
- 网络持续不稳定
- S3 服务暂时不可用

**解决方法**:
1. 检查网络连接
2. 稍后重试
3. 增加 `max_retries` 和 `retry_delay`

---

### 问题 4: 进度文件损坏

**原因**:
- 程序异常退出时写入不完整

**解决方法**:
1. 删除 `.era5_download_progress.json`
2. 重新开始下载
3. 已完成的文件会被自动跳过(通过大小对比)

---

## 🔄 迁移指南

### 从原版迁移到增强版

1. **备份原版**
   ```bash
   cp ERA5download_GUI.py ERA5download_GUI_backup.py
   ```

2. **使用增强版**
   ```bash
   python ERA5download_GUI_v2.py
   ```

3. **兼容性**
   - ✅ 增强版完全兼容原版的下载目录
   - ✅ 已下载的完整文件会被自动跳过
   - ✅ 原版的 `.tmp` 文件会被识别为不完整,重新下载

---

## 📝 技术细节

### 核心方法

#### 1. `save_progress()` - 保存进度
```python
def save_progress(self, progress_data):
    """保存下载进度到 JSON 文件"""
    progress_file = os.path.join(self.current_download_dir, self.progress_file)
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress_data, f, ensure_ascii=False, indent=2)
```

#### 2. `load_progress()` - 加载进度
```python
def load_progress(self, target_dir):
    """从 JSON 文件加载下载进度"""
    progress_file = os.path.join(target_dir, self.progress_file)
    if os.path.exists(progress_file):
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None
```

#### 3. `download_one_with_resume()` - 断点续传下载
```python
def download_one_with_resume(self, f_info, target_dir, cfg, slot_queue):
    """支持断点续传的下载方法"""
    temp_path = local_path + ".tmp"

    # 检查临时文件大小
    downloaded_bytes = 0
    if os.path.exists(temp_path):
        downloaded_bytes = os.path.getsize(temp_path)

    # 使用 Range 请求续传
    self._download_with_retry(f_info, temp_path, downloaded_bytes, sid)
```

#### 4. `_download_with_retry()` - 带重试的下载
```python
def _download_with_retry(self, f_info, temp_path, start_byte, sid):
    """带重试的下载方法,支持 Range 请求"""
    for retry in range(self.max_retries):
        try:
            range_header = f"bytes={start_byte}-"
            response = self.s3_client.get_object(
                Bucket=self.bucket_name,
                Key=f_info['Key'],
                Range=range_header
            )
            # 写入文件...
            return  # 成功,退出重试
        except (ConnectionError, ClientError) as e:
            if retry < self.max_retries - 1:
                time.sleep(self.retry_delay * (2 ** retry))
                # 更新断点位置
                start_byte = os.path.getsize(temp_path)
```

---

## 🎯 最佳实践

### 1. 选择合适的并发数
- **小文件(<10MB)**: 8-10 线程
- **中文件(10-100MB)**: 5-8 线程(默认 5)
- **大文件(>100MB)**: 3-5 线程

### 2. 监控网络状况
- 关注"当前速度"显示
- 速度骤降可能是网络问题
- 速度为 0 可能是连接中断

### 3. 定期检查进度
- 查看"系统日志"了解整体进度
- 已完成/剩余文件数量实时更新

### 4. 处理中断
- 如果频繁中断,考虑:
  - 降低并发数
  - 增加重试次数
  - 检查网络稳定性

---

## 🔮 未来改进方向

### 可能的增强功能

1. **更细粒度的进度显示**
   - 显示每个文件的下载速度
   - 显示预计剩余时间

2. **智能调度**
   - 自动根据网络状况调整并发数
   - 自动调整分块大小

3. **断点续传优化**
   - 支持多分块并行续传
   - 支持校验和验证

4. **GUI 增强**
   - 添加"暂停"按钮(保留所有临时文件)
   - 添加"恢复下载"按钮(检测并恢复未完成任务)
   - 显示下载历史记录

5. **日志系统**
   - 记录所有下载事件到文件
   - 支持错误日志分析

---

## 📚 相关资源

- **AWS S3 Range 请求**: https://docs.aws.amazon.com/AmazonS3/latest/userguide/RangeDownload.html
- **Boto3 S3 客户端**: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html
- **ERA5 数据文档**: https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5

---

## 📞 技术支持

如遇问题,请检查:
1. 网络连接是否正常
2. S3 服务是否可用
3. 磁盘空间是否充足
4. 文件权限是否正确

---

**版本**: v2.0
**更新日期**: 2026-01-19
**主要特性**: 断点续传 + 自动重试 + 进度持久化
